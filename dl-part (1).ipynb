{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11031799,"sourceType":"datasetVersion","datasetId":6870774}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:37:17.434326Z","iopub.execute_input":"2025-03-14T15:37:17.434623Z","iopub.status.idle":"2025-03-14T15:37:18.611446Z","shell.execute_reply.started":"2025-03-14T15:37:17.434598Z","shell.execute_reply":"2025-03-14T15:37:18.610545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:40:57.860386Z","iopub.execute_input":"2025-03-15T16:40:57.860591Z","iopub.status.idle":"2025-03-15T16:40:59.483689Z","shell.execute_reply.started":"2025-03-15T16:40:57.860570Z","shell.execute_reply":"2025-03-15T16:40:59.482864Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/quora/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:04.300312Z","iopub.execute_input":"2025-03-15T16:41:04.300615Z","iopub.status.idle":"2025-03-15T16:41:06.262141Z","shell.execute_reply.started":"2025-03-15T16:41:04.300588Z","shell.execute_reply":"2025-03-15T16:41:06.261185Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:09.642422Z","iopub.execute_input":"2025-03-15T16:41:09.642824Z","iopub.status.idle":"2025-03-15T16:41:09.668842Z","shell.execute_reply.started":"2025-03-15T16:41:09.642775Z","shell.execute_reply":"2025-03-15T16:41:09.667973Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:13.507294Z","iopub.execute_input":"2025-03-15T16:41:13.507619Z","iopub.status.idle":"2025-03-15T16:41:13.586962Z","shell.execute_reply.started":"2025-03-15T16:41:13.507591Z","shell.execute_reply":"2025-03-15T16:41:13.586200Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 404290 entries, 0 to 404289\nData columns (total 6 columns):\n #   Column        Non-Null Count   Dtype \n---  ------        --------------   ----- \n 0   id            404290 non-null  int64 \n 1   qid1          404290 non-null  int64 \n 2   qid2          404290 non-null  int64 \n 3   question1     404289 non-null  object\n 4   question2     404288 non-null  object\n 5   is_duplicate  404290 non-null  int64 \ndtypes: int64(4), object(2)\nmemory usage: 18.5+ MB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df.is_duplicate.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:21.997503Z","iopub.execute_input":"2025-03-15T16:41:21.997834Z","iopub.status.idle":"2025-03-15T16:41:22.007518Z","shell.execute_reply.started":"2025-03-15T16:41:21.997772Z","shell.execute_reply":"2025-03-15T16:41:22.006587Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"is_duplicate\n0    255027\n1    149263\nName: count, dtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df.dropna(axis=0,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:27.106665Z","iopub.execute_input":"2025-03-15T16:41:27.106997Z","iopub.status.idle":"2025-03-15T16:41:27.191731Z","shell.execute_reply.started":"2025-03-15T16:41:27.106973Z","shell.execute_reply":"2025-03-15T16:41:27.191070Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"****Basic features engineering****","metadata":{}},{"cell_type":"code","source":"df['freq_qid1']=df.groupby('qid1')['qid1'].transform('count')\ndf['freq_qid2']=df.groupby('qid2')['qid2'].transform('count')\ndf['q1len']=df['question1'].str.len()\ndf['q2len']=df['question2'].str.len()\ndf['q1_n_words']=df['question1'].apply(lambda x:len(x.split(\" \")))\ndf['q2_n_words']=df['question2'].apply(lambda x:len(x.split(\" \")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:30.803589Z","iopub.execute_input":"2025-03-15T16:41:30.803945Z","iopub.status.idle":"2025-03-15T16:41:31.778855Z","shell.execute_reply.started":"2025-03-15T16:41:30.803914Z","shell.execute_reply":"2025-03-15T16:41:31.777965Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:35.086973Z","iopub.execute_input":"2025-03-15T16:41:35.087373Z","iopub.status.idle":"2025-03-15T16:41:35.102390Z","shell.execute_reply.started":"2025-03-15T16:41:35.087338Z","shell.execute_reply":"2025-03-15T16:41:35.101504Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  freq_qid1  \\\n0  What is the step by step guide to invest in sh...             0          1   \n1  What would happen if the Indian government sto...             0          4   \n2  How can Internet speed be increased by hacking...             0          1   \n3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n4            Which fish would survive in salt water?             0          3   \n\n   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \n0          1     66     57          14          12  \n1          1     51     88           8          13  \n2          1     73     59          14          10  \n3          1     50     65          11           9  \n4          1     76     39          13           7  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>freq_qid1</th>\n      <th>freq_qid2</th>\n      <th>q1len</th>\n      <th>q2len</th>\n      <th>q1_n_words</th>\n      <th>q2_n_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>66</td>\n      <td>57</td>\n      <td>14</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>51</td>\n      <td>88</td>\n      <td>8</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>73</td>\n      <td>59</td>\n      <td>14</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50</td>\n      <td>65</td>\n      <td>11</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>76</td>\n      <td>39</td>\n      <td>13</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def words_common(row1,row2):\n    a=set(row1.split(\" \"))\n    b=set(row2.split(\" \"))\n    return len(a&b)\n\ndef total_words(row1,row2):\n    a=set(row1.split(\" \"))\n    b=set(row2.split(\" \"))\n    return len(a)+len(b)\n\ndf['words_common']=df.apply(lambda x:words_common(x['question1'],x['question2']),axis=1)\ndf['words_total']=df.apply(lambda x:total_words(x['question1'],x['question2']),axis=1)\ndf['words_share']=df.words_common/df.words_total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:40.109357Z","iopub.execute_input":"2025-03-15T16:41:40.109638Z","iopub.status.idle":"2025-03-15T16:41:48.912214Z","shell.execute_reply.started":"2025-03-15T16:41:40.109617Z","shell.execute_reply":"2025-03-15T16:41:48.911512Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:41:58.964906Z","iopub.execute_input":"2025-03-15T16:41:58.965223Z","iopub.status.idle":"2025-03-15T16:41:58.978032Z","shell.execute_reply.started":"2025-03-15T16:41:58.965198Z","shell.execute_reply":"2025-03-15T16:41:58.977289Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  freq_qid1  \\\n0  What is the step by step guide to invest in sh...             0          1   \n1  What would happen if the Indian government sto...             0          4   \n2  How can Internet speed be increased by hacking...             0          1   \n3  Find the remainder when [math]23^{24}[/math] i...             0          1   \n4            Which fish would survive in salt water?             0          3   \n\n   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  words_common  words_total  \\\n0          1     66     57          14          12            10           23   \n1          1     51     88           8          13             4           20   \n2          1     73     59          14          10             3           24   \n3          1     50     65          11           9             0           19   \n4          1     76     39          13           7             2           20   \n\n   words_share  \n0     0.434783  \n1     0.200000  \n2     0.125000  \n3     0.000000  \n4     0.100000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>freq_qid1</th>\n      <th>freq_qid2</th>\n      <th>q1len</th>\n      <th>q2len</th>\n      <th>q1_n_words</th>\n      <th>q2_n_words</th>\n      <th>words_common</th>\n      <th>words_total</th>\n      <th>words_share</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>66</td>\n      <td>57</td>\n      <td>14</td>\n      <td>12</td>\n      <td>10</td>\n      <td>23</td>\n      <td>0.434783</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>51</td>\n      <td>88</td>\n      <td>8</td>\n      <td>13</td>\n      <td>4</td>\n      <td>20</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>73</td>\n      <td>59</td>\n      <td>14</td>\n      <td>10</td>\n      <td>3</td>\n      <td>24</td>\n      <td>0.125000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50</td>\n      <td>65</td>\n      <td>11</td>\n      <td>9</td>\n      <td>0</td>\n      <td>19</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>76</td>\n      <td>39</td>\n      <td>13</td>\n      <td>7</td>\n      <td>2</td>\n      <td>20</td>\n      <td>0.100000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"****Advanced feature engineering****","metadata":{}},{"cell_type":"code","source":"CONTRACTION_MAP = {\n    \"ain't\": \"is not\",\n    \"aren't\": \"are not\",\n    \"can't\": \"cannot\",\n    \"can't've\": \"cannot have\",\n    \"'cause\": \"because\",\n    \"could've\": \"could have\",\n    \"couldn't\": \"could not\",\n    \"couldn't've\": \"could not have\",\n    \"didn't\": \"did not\",\n    \"doesn't\": \"does not\",\n    \"don't\": \"do not\",\n    \"hadn't\": \"had not\",\n    \"hadn't've\": \"had not have\",\n    \"hasn't\": \"has not\",\n    \"haven't\": \"have not\",\n    \"he'd\": \"he would\",\n    \"he'd've\": \"he would have\",\n    \"he'll\": \"he will\",\n    \"he'll've\": \"he he will have\",\n    \"he's\": \"he is\",\n    \"how'd\": \"how did\",\n    \"how'd'y\": \"how do you\",\n    \"how'll\": \"how will\",\n    \"how's\": \"how is\",\n    \"i'd\": \"i would\",\n    \"i'd've\": \"i would have\",\n    \"i'll\": \"i will\",\n    \"i'll've\": \"i will have\",\n    \"i'm\": \"i am\",\n    \"i've\": \"i have\",\n    \"isn't\": \"is not\",\n    \"it'd\": \"it would\",\n    \"it'd've\": \"it would have\",\n    \"it'll\": \"it will\",\n    \"it'll've\": \"it will have\",\n    \"it's\": \"it is\",\n    \"let's\": \"let us\",\n    \"ma'am\": \"madam\",\n    \"mayn't\": \"may not\",\n    \"might've\": \"might have\",\n    \"mightn't\": \"might not\",\n    \"mightn't've\": \"might not have\",\n    \"must've\": \"must have\",\n    \"mustn't\": \"must not\",\n    \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\",\n    \"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\",\n    \"oughtn't\": \"ought not\",\n    \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\n    \"sha'n't\": \"shall not\",\n    \"shan't've\": \"shall not have\",\n    \"she'd\": \"she would\",\n    \"she'd've\": \"she would have\",\n    \"she'll\": \"she will\",\n    \"she'll've\": \"she will have\",\n    \"she's\": \"she is\",\n    \"should've\": \"should have\",\n    \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\",\n    \"so've\": \"so have\",\n    \"so's\": \"so as\",\n    \"that'd\": \"that would\",\n    \"that'd've\": \"that would have\",\n    \"that's\": \"that is\",\n    \"there'd\": \"there would\",\n    \"there'd've\": \"there would have\",\n    \"there's\": \"there is\",\n    \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\",\n    \"they'll\": \"they will\",\n    \"they'll've\": \"they will have\",\n    \"they're\": \"they are\",\n    \"they've\": \"they have\",\n    \"to've\": \"to have\",\n    \"wasn't\": \"was not\",\n    \"we'd\": \"we would\",\n    \"we'd've\": \"we would have\",\n    \"we'll\": \"we will\",\n    \"we'll've\": \"we will have\",\n    \"we're\": \"we are\",\n    \"we've\": \"we have\",\n    \"weren't\": \"were not\",\n    \"what'll\": \"what will\",\n    \"what'll've\": \"what will have\",\n    \"what're\": \"what are\",\n    \"what's\": \"what is\",\n    \"what've\": \"what have\",\n    \"when's\": \"when is\",\n    \"when've\": \"when have\",\n    \"where'd\": \"where did\",\n    \"where's\": \"where is\",\n    \"where've\": \"where have\",\n    \"who'll\": \"who will\",\n    \"who'll've\": \"who will have\",\n    \"who's\": \"who is\",\n    \"who've\": \"who have\",\n    \"why's\": \"why is\",\n    \"why've\": \"why have\",\n    \"will've\": \"will have\",\n    \"won't\": \"will not\",\n    \"won't've\": \"will not have\",\n    \"would've\": \"would have\",\n    \"wouldn't\": \"would not\",\n    \"wouldn't've\": \"would not have\",\n    \"y'all\": \"you all\",\n    \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\",\n    \"y'all're\": \"you all are\",\n    \"y'all've\": \"you all have\",\n    \"you'd\": \"you would\",\n    \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\",\n    \"you'll've\": \"you will have\",\n    \"you're\": \"you are\",\n    \"you've\": \"you have\"\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:42:46.570870Z","iopub.execute_input":"2025-03-15T16:42:46.571173Z","iopub.status.idle":"2025-03-15T16:42:46.579046Z","shell.execute_reply.started":"2025-03-15T16:42:46.571152Z","shell.execute_reply":"2025-03-15T16:42:46.578049Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#defining a function to expand contracted words\ndef contract_expand(text):\n    new_text=\"\"\n    text=text.lower()\n    for word in text.split():\n        if word in CONTRACTION_MAP.keys():\n            new_text=new_text+CONTRACTION_MAP[word]\n            new_text=new_text+\" \"\n        else:\n            new_text=new_text+word\n            new_text=new_text+\" \"\n    return new_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:42:51.454660Z","iopub.execute_input":"2025-03-15T16:42:51.454997Z","iopub.status.idle":"2025-03-15T16:42:51.459435Z","shell.execute_reply.started":"2025-03-15T16:42:51.454969Z","shell.execute_reply":"2025-03-15T16:42:51.458675Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#checking our function\nsample_text=\"I dON't eat banana\"\ncontract_expand(sample_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:42:57.662133Z","iopub.execute_input":"2025-03-15T16:42:57.662441Z","iopub.status.idle":"2025-03-15T16:42:57.667527Z","shell.execute_reply.started":"2025-03-15T16:42:57.662413Z","shell.execute_reply":"2025-03-15T16:42:57.666610Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'i do not eat banana '"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"**Now we will apply this function to our dataset for qustion1 and question2**","metadata":{}},{"cell_type":"code","source":"df['question1']=df.question1.apply(contract_expand)\ndf['question2']=df.question2.apply(contract_expand)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:00.973308Z","iopub.execute_input":"2025-03-15T16:43:00.973727Z","iopub.status.idle":"2025-03-15T16:43:03.873082Z","shell.execute_reply.started":"2025-03-15T16:43:00.973689Z","shell.execute_reply":"2025-03-15T16:43:03.872144Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"****Removing punctuation****\n\n","metadata":{}},{"cell_type":"code","source":"#defining function\ndef remove_punctuation_and_links(text):\n    pattern1=re.compile('https?\\S+|www.\\S+|#[a-zA-Z0-9]+')\n    text=re.sub(pattern1,\"\",text)\n    pattern2=\"[^\\w\\s]\"\n\n    return re.sub(pattern2,\"\",text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:08.239425Z","iopub.execute_input":"2025-03-15T16:43:08.239730Z","iopub.status.idle":"2025-03-15T16:43:08.243619Z","shell.execute_reply.started":"2025-03-15T16:43:08.239702Z","shell.execute_reply":"2025-03-15T16:43:08.242905Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom matplotlib import style\nstyle.use(\"ggplot\")\n\nimport regex as re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\n\n\nfrom fuzzywuzzy import fuzz\nfrom nltk.tokenize import word_tokenize\n\nimport spacy\nfrom tqdm import tqdm\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:12.054289Z","iopub.execute_input":"2025-03-15T16:43:12.054566Z","iopub.status.idle":"2025-03-15T16:43:19.141671Z","shell.execute_reply.started":"2025-03-15T16:43:12.054543Z","shell.execute_reply":"2025-03-15T16:43:19.141017Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import re\nimport string\n\ndef remove_punctuation_and_links(text):\n    # Remove URLs\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    # Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    return text\n\n# Sample text\nsample_text = \"What a shot! Sky is in absolute form this year. (sky is nickname for surya kumar yadav .for reference https://en.wikipedia.org/wiki/Suryakumar_Yadav)\"\n\n# Call the function\ncleaned_text = remove_punctuation_and_links(sample_text)\nprint(cleaned_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:25.908155Z","iopub.execute_input":"2025-03-15T16:43:25.908684Z","iopub.status.idle":"2025-03-15T16:43:25.915141Z","shell.execute_reply.started":"2025-03-15T16:43:25.908657Z","shell.execute_reply":"2025-03-15T16:43:25.913764Z"}},"outputs":[{"name":"stdout","text":"What a shot Sky is in absolute form this year sky is nickname for surya kumar yadav for reference \n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"%%time\n\ndf['question1']=df.question1.apply(remove_punctuation_and_links)\ndf['question2']=df.question2.apply(remove_punctuation_and_links)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:37.091969Z","iopub.execute_input":"2025-03-15T16:43:37.092250Z","iopub.status.idle":"2025-03-15T16:43:41.053997Z","shell.execute_reply.started":"2025-03-15T16:43:37.092227Z","shell.execute_reply":"2025-03-15T16:43:41.053209Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 3.9 s, sys: 57.1 ms, total: 3.96 s\nWall time: 3.96 s\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"****Word Tokenization and Stemming****","metadata":{}},{"cell_type":"code","source":"ps=PorterStemmer()\n\ndef stem(text):\n    tokens=text.split()\n    token_stemmed=[ps.stem(word) for word in tokens]\n    new_text=remove_punctuation_and_links(str(token_stemmed))\n    return new_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:46.608849Z","iopub.execute_input":"2025-03-15T16:43:46.609246Z","iopub.status.idle":"2025-03-15T16:43:46.613704Z","shell.execute_reply.started":"2025-03-15T16:43:46.609216Z","shell.execute_reply":"2025-03-15T16:43:46.612740Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#checking our stem function\na=\"my name is riya ,i follow arijit singh and i m followed by my juniors\"\n\nstem(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:50.518144Z","iopub.execute_input":"2025-03-15T16:43:50.518423Z","iopub.status.idle":"2025-03-15T16:43:50.523604Z","shell.execute_reply.started":"2025-03-15T16:43:50.518403Z","shell.execute_reply":"2025-03-15T16:43:50.522884Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'my name is riya i follow arijit singh and i m follow by my junior'"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"Lets apply this on dataset now","metadata":{}},{"cell_type":"code","source":"%%time\ndf['question1']=df.question1.apply(stem)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:43:54.116591Z","iopub.execute_input":"2025-03-15T16:43:54.116913Z","iopub.status.idle":"2025-03-15T16:44:54.621972Z","shell.execute_reply.started":"2025-03-15T16:43:54.116887Z","shell.execute_reply":"2025-03-15T16:44:54.621190Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 1min, sys: 37.8 ms, total: 1min\nWall time: 1min\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"%%time\ndf['question2']=df.question2.apply(stem)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:45:55.712045Z","iopub.execute_input":"2025-03-15T16:45:55.712325Z","iopub.status.idle":"2025-03-15T16:46:56.958695Z","shell.execute_reply.started":"2025-03-15T16:45:55.712304Z","shell.execute_reply":"2025-03-15T16:46:56.957823Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 1min 1s, sys: 55.3 ms, total: 1min 1s\nWall time: 1min 1s\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Advance Feature Creation","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\ntry:\n    stop_words = set(stopwords.words('english'))\n    print(\"Stopwords loaded successfully!\")\nexcept LookupError:\n    print(\"Stopwords not found!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:48:12.183436Z","iopub.execute_input":"2025-03-15T16:48:12.183716Z","iopub.status.idle":"2025-03-15T16:48:12.189040Z","shell.execute_reply.started":"2025-03-15T16:48:12.183693Z","shell.execute_reply":"2025-03-15T16:48:12.188242Z"}},"outputs":[{"name":"stdout","text":"Stopwords loaded successfully!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\nstopword = list(ENGLISH_STOP_WORDS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:48:16.428518Z","iopub.execute_input":"2025-03-15T16:48:16.428822Z","iopub.status.idle":"2025-03-15T16:48:16.432568Z","shell.execute_reply.started":"2025-03-15T16:48:16.428778Z","shell.execute_reply":"2025-03-15T16:48:16.431621Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def get_features(q1,q2):\n    \n    token_features=[0]*10\n    \n    #converting strings to tokens\n    q1_tokens=q1.split()\n    q2_tokens=q2.split()\n    \n    \n    if len(q1_tokens)==0 or len(q2_tokens)==0:\n        return token_features\n    \n    #getting words without stopwords\n    q1_words=set(word for word in q1_tokens if word not in stopword)\n    q2_words=set(word for word in q2_tokens if word not in stopword)\n    \n    #getting stopwords\n    q1_sw=set(word for word in q1_tokens if word in stopword)\n    q2_sw=set(word for word in q2_tokens if word in stopword)\n    \n    token_features[0]=len(q1_words&q2_words)/(min(len(q1_words),len(q2_words))+0.0001)\n    token_features[1]=len(q1_words&q2_words)/(max(len(q1_words),len(q2_words))+0.0001)\n    token_features[2]=len(q1_sw&q2_sw)/(min(len(q1_sw),len(q2_sw))+0.0001)   #for safe division\n    token_features[3]=len(q1_sw&q2_sw)/(max(len(q1_sw),len(q2_sw))+0.0001)\n    token_features[4]=len(set(q1_tokens)&set(q2_tokens))/(min(len(q1_tokens),len(q2_tokens))+0.0001)\n    token_features[5]=len(set(q1_tokens)&set(q2_tokens))/(max(len(q1_tokens),len(q2_tokens))+0.0001)\n    \n    token_features[6]=int(q1_tokens[-1]==q2_tokens[-1])\n    token_features[7]=int(q1_tokens[0]==q2_tokens[0])\n    token_features[8]=len(q1_tokens)-len(q2_tokens)\n    token_features[9]=(len(q1_tokens)+len(q2_tokens))/2\n    \n    \n    return token_features\n    \n    \n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:49:57.402390Z","iopub.execute_input":"2025-03-15T16:49:57.402747Z","iopub.status.idle":"2025-03-15T16:49:57.409956Z","shell.execute_reply.started":"2025-03-15T16:49:57.402716Z","shell.execute_reply":"2025-03-15T16:49:57.409149Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"%%time\n\nprint(\"Creating features....\")\ndf['cwc_min']=df.apply(lambda x:get_features(x['question1'],x['question2'])[0],axis=1)\ndf['cwc_max']=df.apply(lambda x:get_features(x['question1'],x['question2'])[1],axis=1)\ndf['csc_min']=df.apply(lambda x:get_features(x['question1'],x['question2'])[2],axis=1)\ndf['csc_max']=df.apply(lambda x:get_features(x['question1'],x['question2'])[3],axis=1)\ndf['ctc_min']=df.apply(lambda x:get_features(x['question1'],x['question2'])[4],axis=1)\ndf['ctc_max']=df.apply(lambda x:get_features(x['question1'],x['question2'])[5],axis=1)\ndf['last_word_eq']=df.apply(lambda x:get_features(x['question1'],x['question2'])[6],axis=1)\ndf['first_word_eq']=df.apply(lambda x:get_features(x['question1'],x['question2'])[7],axis=1)\ndf['abs_diff']=df.apply(lambda x:get_features(x['question1'],x['question2'])[8],axis=1)\ndf['mean_length']=df.apply(lambda x:get_features(x['question1'],x['question2'])[9],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T16:50:04.085566Z","iopub.execute_input":"2025-03-15T16:50:04.085900Z","iopub.status.idle":"2025-03-15T17:00:08.280170Z","shell.execute_reply.started":"2025-03-15T16:50:04.085871Z","shell.execute_reply":"2025-03-15T17:00:08.279403Z"}},"outputs":[{"name":"stdout","text":"Creating features....\nCPU times: user 10min 2s, sys: 1.59 s, total: 10min 4s\nWall time: 10min 4s\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"pd.set_option(\"display.max_columns\",None)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:07:18.857112Z","iopub.execute_input":"2025-03-15T17:07:18.857401Z","iopub.status.idle":"2025-03-15T17:07:18.873860Z","shell.execute_reply.started":"2025-03-15T17:07:18.857378Z","shell.execute_reply":"2025-03-15T17:07:18.872883Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  what is the step by step guid to invest in sha...   \n1   1     3     4     what is the stori of kohinoor kohinoor diamond   \n2   2     5     6  how can i increas the speed of my internet con...   \n3   3     7     8        whi am i mental veri lone how can i solv it   \n4   4     9    10  which one dissolv in water quikli sugar salt m...   \n\n                                           question2  is_duplicate  freq_qid1  \\\n0  what is the step by step guid to invest in sha...             0          1   \n1  what would happen if the indian govern stole t...             0          4   \n2  how can internet speed be increas by hack thro...             0          1   \n3  find the remaind when math2324math is divid by...             0          1   \n4              which fish would surviv in salt water             0          3   \n\n   freq_qid2  q1len  q2len  q1_n_words  q2_n_words  words_common  words_total  \\\n0          1     66     57          14          12            10           23   \n1          1     51     88           8          13             4           20   \n2          1     73     59          14          10             3           24   \n3          1     50     65          11           9             0           19   \n4          1     76     39          13           7             2           20   \n\n   words_share   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n0     0.434783  0.999980  0.833319  0.999983  0.999983  0.916659  0.785709   \n1     0.200000  0.666644  0.333328  0.499988  0.399992  0.499994  0.307690   \n2     0.125000  0.599988  0.499992  0.399992  0.249997  0.499995  0.357140   \n3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n4     0.100000  0.499988  0.222220  0.666644  0.499988  0.571420  0.307690   \n\n   last_word_eq  first_word_eq  abs_diff  mean_length  \n0             0              1         2         13.0  \n1             0              1        -5         10.5  \n2             0              1         4         12.0  \n3             0              0         2         10.0  \n4             0              1         6         10.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n      <th>freq_qid1</th>\n      <th>freq_qid2</th>\n      <th>q1len</th>\n      <th>q2len</th>\n      <th>q1_n_words</th>\n      <th>q2_n_words</th>\n      <th>words_common</th>\n      <th>words_total</th>\n      <th>words_share</th>\n      <th>cwc_min</th>\n      <th>cwc_max</th>\n      <th>csc_min</th>\n      <th>csc_max</th>\n      <th>ctc_min</th>\n      <th>ctc_max</th>\n      <th>last_word_eq</th>\n      <th>first_word_eq</th>\n      <th>abs_diff</th>\n      <th>mean_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>what is the step by step guid to invest in sha...</td>\n      <td>what is the step by step guid to invest in sha...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>66</td>\n      <td>57</td>\n      <td>14</td>\n      <td>12</td>\n      <td>10</td>\n      <td>23</td>\n      <td>0.434783</td>\n      <td>0.999980</td>\n      <td>0.833319</td>\n      <td>0.999983</td>\n      <td>0.999983</td>\n      <td>0.916659</td>\n      <td>0.785709</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>what is the stori of kohinoor kohinoor diamond</td>\n      <td>what would happen if the indian govern stole t...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>51</td>\n      <td>88</td>\n      <td>8</td>\n      <td>13</td>\n      <td>4</td>\n      <td>20</td>\n      <td>0.200000</td>\n      <td>0.666644</td>\n      <td>0.333328</td>\n      <td>0.499988</td>\n      <td>0.399992</td>\n      <td>0.499994</td>\n      <td>0.307690</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-5</td>\n      <td>10.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>how can i increas the speed of my internet con...</td>\n      <td>how can internet speed be increas by hack thro...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>73</td>\n      <td>59</td>\n      <td>14</td>\n      <td>10</td>\n      <td>3</td>\n      <td>24</td>\n      <td>0.125000</td>\n      <td>0.599988</td>\n      <td>0.499992</td>\n      <td>0.399992</td>\n      <td>0.249997</td>\n      <td>0.499995</td>\n      <td>0.357140</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>whi am i mental veri lone how can i solv it</td>\n      <td>find the remaind when math2324math is divid by...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>50</td>\n      <td>65</td>\n      <td>11</td>\n      <td>9</td>\n      <td>0</td>\n      <td>19</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>which one dissolv in water quikli sugar salt m...</td>\n      <td>which fish would surviv in salt water</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>76</td>\n      <td>39</td>\n      <td>13</td>\n      <td>7</td>\n      <td>2</td>\n      <td>20</td>\n      <td>0.100000</td>\n      <td>0.499988</td>\n      <td>0.222220</td>\n      <td>0.666644</td>\n      <td>0.499988</td>\n      <td>0.571420</td>\n      <td>0.307690</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"#creatuing fuzzy features\nprint(\"Creating fuzzy feautures .....\")\n\ndf['fuzz_ratio']=df.apply(lambda x:fuzz.QRatio(x['question1'],x['question2']),axis=1)\ndf['fuzz_partial_ratio']=df.apply(lambda x:fuzz.partial_ratio(x['question1'],x['question2']),axis=1)\ndf['token_sort_ratio']=df.apply(lambda x:fuzz.token_sort_ratio(x['question1'],x['question2']),axis=1)\ndf['token_set_ratio']=df.apply(lambda x:fuzz.token_set_ratio(x['question1'],x['question2']),axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:07:26.000425Z","iopub.execute_input":"2025-03-15T17:07:26.000726Z","iopub.status.idle":"2025-03-15T17:20:00.720977Z","shell.execute_reply.started":"2025-03-15T17:07:26.000702Z","shell.execute_reply":"2025-03-15T17:20:00.719872Z"}},"outputs":[{"name":"stdout","text":"Creating fuzzy feautures .....\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"print(\"The shape of the data is\",df.shape)\nprint(df.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:20:08.300180Z","iopub.execute_input":"2025-03-15T17:20:08.300469Z","iopub.status.idle":"2025-03-15T17:20:08.306167Z","shell.execute_reply.started":"2025-03-15T17:20:08.300447Z","shell.execute_reply":"2025-03-15T17:20:08.305284Z"}},"outputs":[{"name":"stdout","text":"The shape of the data is (404287, 29)\nIndex(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n       'freq_qid1', 'freq_qid2', 'q1len', 'q2len', 'q1_n_words', 'q2_n_words',\n       'words_common', 'words_total', 'words_share', 'cwc_min', 'cwc_max',\n       'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq',\n       'first_word_eq', 'abs_diff', 'mean_length', 'fuzz_ratio',\n       'fuzz_partial_ratio', 'token_sort_ratio', 'token_set_ratio'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')\n\n# Combine question1 and question2 into a single text field\ndf['text'] = df['question1'].fillna('') + ' ' + df['question2'].fillna('')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:20:16.817259Z","iopub.execute_input":"2025-03-15T17:20:16.817573Z","iopub.status.idle":"2025-03-15T17:20:17.174390Z","shell.execute_reply.started":"2025-03-15T17:20:16.817544Z","shell.execute_reply":"2025-03-15T17:20:17.173094Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"df['tokens'] = df['text'].apply(lambda x: word_tokenize(str(x).lower()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:20:22.470170Z","iopub.execute_input":"2025-03-15T17:20:22.470457Z","iopub.status.idle":"2025-03-15T17:21:09.711718Z","shell.execute_reply.started":"2025-03-15T17:20:22.470435Z","shell.execute_reply":"2025-03-15T17:21:09.711058Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from gensim.models import Word2Vec\n\nw2v_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:21:20.534671Z","iopub.execute_input":"2025-03-15T17:21:20.535018Z","iopub.status.idle":"2025-03-15T17:22:10.502478Z","shell.execute_reply.started":"2025-03-15T17:21:20.534989Z","shell.execute_reply":"2025-03-15T17:22:10.501755Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['tokens'])\nsequences = tokenizer.texts_to_sequences(df['tokens'])\nword_index = tokenizer.word_index\nvocab_size = len(word_index) + 1\n\nmaxlen = 100\nX = pad_sequences(sequences, maxlen=maxlen)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:22:23.560889Z","iopub.execute_input":"2025-03-15T17:22:23.561454Z","iopub.status.idle":"2025-03-15T17:22:44.603205Z","shell.execute_reply.started":"2025-03-15T17:22:23.561426Z","shell.execute_reply":"2025-03-15T17:22:44.602476Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"import numpy as np\n\nembedding_dim = 100\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, i in word_index.items():\n    if word in w2v_model.wv:\n        embedding_matrix[i] = w2v_model.wv[word]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:22:47.567719Z","iopub.execute_input":"2025-03-15T17:22:47.568427Z","iopub.status.idle":"2025-03-15T17:22:47.846802Z","shell.execute_reply.started":"2025-03-15T17:22:47.568397Z","shell.execute_reply":"2025-03-15T17:22:47.846129Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ny = df['is_duplicate'].values  # This is the label column\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:22:54.018432Z","iopub.execute_input":"2025-03-15T17:22:54.018756Z","iopub.status.idle":"2025-03-15T17:22:54.123380Z","shell.execute_reply.started":"2025-03-15T17:22:54.018732Z","shell.execute_reply":"2025-03-15T17:22:54.122682Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n\nmodel_rnn = Sequential()\nmodel_rnn.add(Embedding(input_dim=vocab_size,\n                        output_dim=embedding_dim,\n                        weights=[embedding_matrix],\n                        input_length=maxlen,\n                        trainable=False))\nmodel_rnn.add(SimpleRNN(64))\nmodel_rnn.add(Dense(1, activation='sigmoid'))\n\nmodel_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_rnn.summary()\n\n# Train\nhistory_rnn = model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate\nloss_rnn, acc_rnn = model_rnn.evaluate(X_test, y_test)\nprint(f\"🧠 RNN Test Accuracy: {acc_rnn:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:23:15.531832Z","iopub.execute_input":"2025-03-15T17:23:15.532145Z","iopub.status.idle":"2025-03-15T17:40:10.540493Z","shell.execute_reply.started":"2025-03-15T17:23:15.532119Z","shell.execute_reply":"2025-03-15T17:40:10.539815Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │       \u001b[38;5;34m8,696,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 10ms/step - accuracy: 0.6914 - loss: 0.5958 - val_accuracy: 0.7114 - val_loss: 0.5697\nEpoch 2/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 10ms/step - accuracy: 0.7308 - loss: 0.5475 - val_accuracy: 0.7335 - val_loss: 0.5380\nEpoch 3/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 10ms/step - accuracy: 0.7292 - loss: 0.5488 - val_accuracy: 0.7287 - val_loss: 0.5404\nEpoch 4/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 10ms/step - accuracy: 0.7361 - loss: 0.5390 - val_accuracy: 0.7279 - val_loss: 0.5467\nEpoch 5/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 10ms/step - accuracy: 0.7374 - loss: 0.5379 - val_accuracy: 0.7370 - val_loss: 0.5355\nEpoch 6/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 10ms/step - accuracy: 0.7367 - loss: 0.5383 - val_accuracy: 0.7367 - val_loss: 0.5361\nEpoch 7/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 10ms/step - accuracy: 0.7413 - loss: 0.5317 - val_accuracy: 0.7399 - val_loss: 0.5325\nEpoch 8/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 10ms/step - accuracy: 0.7424 - loss: 0.5280 - val_accuracy: 0.7324 - val_loss: 0.5437\nEpoch 9/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 10ms/step - accuracy: 0.7410 - loss: 0.5317 - val_accuracy: 0.7339 - val_loss: 0.5415\nEpoch 10/10\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 10ms/step - accuracy: 0.7394 - loss: 0.5352 - val_accuracy: 0.7349 - val_loss: 0.5368\n\u001b[1m2527/2527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.7348 - loss: 0.5369\n🧠 RNN Test Accuracy: 0.7349\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"model_rnn.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:40:35.510278Z","iopub.execute_input":"2025-03-15T17:40:35.510567Z","iopub.status.idle":"2025-03-15T17:40:35.527164Z","shell.execute_reply.started":"2025-03-15T17:40:35.510543Z","shell.execute_reply":"2025-03-15T17:40:35.526362Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m8,696,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m10,560\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,560</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,727,977\u001b[0m (33.29 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,727,977</span> (33.29 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,625\u001b[0m (41.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,625</span> (41.50 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m21,252\u001b[0m (83.02 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,252</span> (83.02 KB)\n</pre>\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dropout, Dense, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Step 1: Compute class weights to handle imbalance\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Step 2: Define the model\nmodel_rnn = Sequential()\nmodel_rnn.add(Embedding(input_dim=vocab_size,\n                        output_dim=embedding_dim,\n                        weights=[embedding_matrix],\n                        input_length=maxlen,\n                        trainable=False))  # Freeze embedding layer\n\n# Add Bidirectional RNN\nmodel_rnn.add(Bidirectional(SimpleRNN(64)))\n\n# Dropout for regularization\nmodel_rnn.add(Dropout(0.5))\n\n# Output layer\nmodel_rnn.add(Dense(1, activation='sigmoid'))\n\n# Step 3: Compile the model\noptimizer = Adam(learning_rate=0.001)\nmodel_rnn.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Step 4: Print model summary\nmodel_rnn.summary()\n\n# Step 5: Train the model\nhistory_rnn = model_rnn.fit(\n    X_train, y_train,\n    epochs=10,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    class_weight=class_weights,\n    verbose=1\n)\n\n# Step 6: Evaluate performance\nloss_rnn, acc_rnn = model_rnn.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\n📈 Improved RNN Test Accuracy: {acc_rnn:.4f}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:41:03.542442Z","iopub.execute_input":"2025-03-15T17:41:03.542751Z","iopub.status.idle":"2025-03-15T17:57:48.361262Z","shell.execute_reply.started":"2025-03-15T17:41:03.542727Z","shell.execute_reply":"2025-03-15T17:57:48.360292Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m8,696,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 20ms/step - accuracy: 0.6486 - loss: 0.6421 - val_accuracy: 0.6924 - val_loss: 0.5977\nEpoch 2/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7035 - loss: 0.5869 - val_accuracy: 0.7216 - val_loss: 0.5605\nEpoch 3/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7136 - loss: 0.5756 - val_accuracy: 0.7085 - val_loss: 0.5849\nEpoch 4/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 19ms/step - accuracy: 0.7172 - loss: 0.5705 - val_accuracy: 0.7341 - val_loss: 0.5454\nEpoch 5/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7200 - loss: 0.5669 - val_accuracy: 0.7386 - val_loss: 0.5378\nEpoch 6/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7189 - loss: 0.5646 - val_accuracy: 0.7117 - val_loss: 0.5692\nEpoch 7/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7226 - loss: 0.5643 - val_accuracy: 0.7032 - val_loss: 0.5825\nEpoch 8/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7214 - loss: 0.5689 - val_accuracy: 0.7352 - val_loss: 0.5431\nEpoch 9/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7240 - loss: 0.5641 - val_accuracy: 0.7249 - val_loss: 0.5561\nEpoch 10/10\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 19ms/step - accuracy: 0.7217 - loss: 0.5637 - val_accuracy: 0.7105 - val_loss: 0.5671\n\n📈 Improved RNN Test Accuracy: 0.7105\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Define LSTM model\nmodel_lstm = Sequential()\nmodel_lstm.add(Embedding(input_dim=vocab_size,\n                         output_dim=embedding_dim,\n                         weights=[embedding_matrix],\n                         input_length=maxlen,\n                         trainable=False))\nmodel_lstm.add(LSTM(128))\nmodel_lstm.add(Dropout(0.5))\nmodel_lstm.add(Dense(1, activation='sigmoid'))\n\n# Compile model\nmodel_lstm.compile(optimizer=Adam(learning_rate=0.001),\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\n# Summary\nmodel_lstm.summary()\n\n# Train\nhistory_lstm = model_lstm.fit(X_train, y_train,\n                              epochs=30,\n                              batch_size=64,\n                              validation_data=(X_test, y_test),\n                              class_weight=class_weights,\n                              verbose=1)\n\n# Evaluate\nloss_lstm, acc_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\n🔁 LSTM Test Accuracy: {acc_lstm:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T17:58:41.235166Z","iopub.execute_input":"2025-03-15T17:58:41.235471Z","iopub.status.idle":"2025-03-15T18:16:50.214986Z","shell.execute_reply.started":"2025-03-15T17:58:41.235448Z","shell.execute_reply":"2025-03-15T18:16:50.214038Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m8,696,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - accuracy: 0.7064 - loss: 0.5654 - val_accuracy: 0.7570 - val_loss: 0.4882\nEpoch 2/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7556 - loss: 0.4917 - val_accuracy: 0.7716 - val_loss: 0.4634\nEpoch 3/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.4571 - val_accuracy: 0.7649 - val_loss: 0.4733\nEpoch 4/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.7900 - loss: 0.4328 - val_accuracy: 0.7798 - val_loss: 0.4502\nEpoch 5/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8031 - loss: 0.4108 - val_accuracy: 0.7794 - val_loss: 0.4545\nEpoch 6/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8117 - loss: 0.3937 - val_accuracy: 0.7866 - val_loss: 0.4444\nEpoch 7/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8210 - loss: 0.3776 - val_accuracy: 0.7863 - val_loss: 0.4454\nEpoch 8/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8282 - loss: 0.3656 - val_accuracy: 0.7859 - val_loss: 0.4453\nEpoch 9/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8335 - loss: 0.3552 - val_accuracy: 0.7902 - val_loss: 0.4455\nEpoch 10/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 0.3438 - val_accuracy: 0.7917 - val_loss: 0.4465\nEpoch 11/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8466 - loss: 0.3325 - val_accuracy: 0.7905 - val_loss: 0.4523\nEpoch 12/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8509 - loss: 0.3253 - val_accuracy: 0.7907 - val_loss: 0.4504\nEpoch 13/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.3176 - val_accuracy: 0.7890 - val_loss: 0.4560\nEpoch 14/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8566 - loss: 0.3134 - val_accuracy: 0.7913 - val_loss: 0.4626\nEpoch 15/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8586 - loss: 0.3089 - val_accuracy: 0.7810 - val_loss: 0.4782\nEpoch 16/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8611 - loss: 0.3055 - val_accuracy: 0.7832 - val_loss: 0.4804\nEpoch 17/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.3007 - val_accuracy: 0.7823 - val_loss: 0.4826\nEpoch 18/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.2941 - val_accuracy: 0.7857 - val_loss: 0.4859\nEpoch 19/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.8668 - loss: 0.2941 - val_accuracy: 0.7882 - val_loss: 0.4843\nEpoch 20/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8693 - loss: 0.2900 - val_accuracy: 0.7848 - val_loss: 0.4799\nEpoch 21/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8702 - loss: 0.2884 - val_accuracy: 0.7820 - val_loss: 0.4883\nEpoch 22/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7ms/step - accuracy: 0.8708 - loss: 0.2882 - val_accuracy: 0.7845 - val_loss: 0.5016\nEpoch 23/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8712 - loss: 0.2857 - val_accuracy: 0.7854 - val_loss: 0.4818\nEpoch 24/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8706 - loss: 0.2879 - val_accuracy: 0.7857 - val_loss: 0.4910\nEpoch 25/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.2868 - val_accuracy: 0.7852 - val_loss: 0.4834\nEpoch 26/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.2867 - val_accuracy: 0.7849 - val_loss: 0.4887\nEpoch 27/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8695 - loss: 0.2903 - val_accuracy: 0.7820 - val_loss: 0.4943\nEpoch 28/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8737 - loss: 0.2840 - val_accuracy: 0.7844 - val_loss: 0.4970\nEpoch 29/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8713 - loss: 0.2867 - val_accuracy: 0.7816 - val_loss: 0.4995\nEpoch 30/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.2857 - val_accuracy: 0.7858 - val_loss: 0.4859\n\n🔁 LSTM Test Accuracy: 0.7858\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\nmodel_lstm = Sequential()\nmodel_lstm.add(Embedding(input_dim=vocab_size,\n                         output_dim=embedding_dim,\n                         weights=[embedding_matrix],\n                         input_length=maxlen,\n                         trainable=False))\nmodel_lstm.add(LSTM(64))\nmodel_lstm.add(Dense(1, activation='sigmoid'))\n\nmodel_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel_lstm.summary()\n\n# Train\nhistory_lstm = model_lstm.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate\nloss, accuracy = model_lstm.evaluate(X_test, y_test)\nprint(f\"LSTM Test Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:17:17.655367Z","iopub.execute_input":"2025-03-15T18:17:17.655660Z","iopub.status.idle":"2025-03-15T18:49:10.937527Z","shell.execute_reply.started":"2025-03-15T18:17:17.655638Z","shell.execute_reply":"2025-03-15T18:49:10.936872Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │       \u001b[38;5;34m8,696,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,696,100\u001b[0m (33.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,696,100</span> (33.17 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 6ms/step - accuracy: 0.7358 - loss: 0.5274 - val_accuracy: 0.7681 - val_loss: 0.4744\nEpoch 2/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.7780 - loss: 0.4611 - val_accuracy: 0.7760 - val_loss: 0.4604\nEpoch 3/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.7933 - loss: 0.4346 - val_accuracy: 0.7827 - val_loss: 0.4496\nEpoch 4/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8040 - loss: 0.4164 - val_accuracy: 0.7859 - val_loss: 0.4464\nEpoch 5/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8147 - loss: 0.4007 - val_accuracy: 0.7869 - val_loss: 0.4450\nEpoch 6/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8197 - loss: 0.3914 - val_accuracy: 0.7889 - val_loss: 0.4451\nEpoch 7/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.3787 - val_accuracy: 0.7900 - val_loss: 0.4438\nEpoch 8/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8297 - loss: 0.3718 - val_accuracy: 0.7895 - val_loss: 0.4480\nEpoch 9/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8339 - loss: 0.3638 - val_accuracy: 0.7923 - val_loss: 0.4473\nEpoch 10/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8369 - loss: 0.3595 - val_accuracy: 0.7907 - val_loss: 0.4529\nEpoch 11/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.3521 - val_accuracy: 0.7909 - val_loss: 0.4526\nEpoch 12/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8444 - loss: 0.3475 - val_accuracy: 0.7890 - val_loss: 0.4565\nEpoch 13/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 0.3439 - val_accuracy: 0.7913 - val_loss: 0.4560\nEpoch 14/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8479 - loss: 0.3394 - val_accuracy: 0.7879 - val_loss: 0.4631\nEpoch 15/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8509 - loss: 0.3348 - val_accuracy: 0.7904 - val_loss: 0.4642\nEpoch 16/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8515 - loss: 0.3339 - val_accuracy: 0.7880 - val_loss: 0.4650\nEpoch 17/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8532 - loss: 0.3311 - val_accuracy: 0.7883 - val_loss: 0.4668\nEpoch 18/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 0.3267 - val_accuracy: 0.7884 - val_loss: 0.4672\nEpoch 19/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4033 - val_accuracy: 0.7732 - val_loss: 0.4759\nEpoch 20/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8240 - loss: 0.3829 - val_accuracy: 0.7905 - val_loss: 0.4571\nEpoch 21/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.3324 - val_accuracy: 0.7877 - val_loss: 0.4687\nEpoch 22/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 0.3265 - val_accuracy: 0.7897 - val_loss: 0.4675\nEpoch 23/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8571 - loss: 0.3221 - val_accuracy: 0.7891 - val_loss: 0.4695\nEpoch 24/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.3200 - val_accuracy: 0.7871 - val_loss: 0.4717\nEpoch 25/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8611 - loss: 0.3155 - val_accuracy: 0.7876 - val_loss: 0.4779\nEpoch 26/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.3115 - val_accuracy: 0.7855 - val_loss: 0.4789\nEpoch 27/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8630 - loss: 0.3124 - val_accuracy: 0.7866 - val_loss: 0.4769\nEpoch 28/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.3115 - val_accuracy: 0.7877 - val_loss: 0.4834\nEpoch 29/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.3104 - val_accuracy: 0.7862 - val_loss: 0.4838\nEpoch 30/30\n\u001b[1m10108/10108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 6ms/step - accuracy: 0.8637 - loss: 0.3092 - val_accuracy: 0.7863 - val_loss: 0.4840\n\u001b[1m2527/2527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4837\nLSTM Test Accuracy: 0.7863\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Define LSTM model\nmodel_lstm = Sequential()\nmodel_lstm.add(Embedding(input_dim=vocab_size,\n                         output_dim=embedding_dim,\n                         weights=[embedding_matrix],\n                         input_length=maxlen,\n                         trainable=False))\nmodel_lstm.add(LSTM(128))\nmodel_lstm.add(Dropout(0.5))\nmodel_lstm.add(Dense(1, activation='sigmoid'))\n\n# Compile model\nmodel_lstm.compile(optimizer=Adam(learning_rate=0.001),\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\n\n\n# Train\nhistory_lstm = model_lstm.fit(X_train, y_train,\n                              epochs=20,\n                              batch_size=64,\n                              validation_data=(X_test, y_test),\n                              class_weight=class_weights,\n                              verbose=1)\n\n# Evaluate\nloss_lstm, acc_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\n🔁 LSTM Test Accuracy: {acc_lstm:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T17:38:07.649436Z","iopub.execute_input":"2025-03-14T17:38:07.649738Z","iopub.status.idle":"2025-03-14T17:50:11.479999Z","shell.execute_reply.started":"2025-03-14T17:38:07.649717Z","shell.execute_reply":"2025-03-14T17:50:11.479148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_lstm.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T17:50:57.379197Z","iopub.execute_input":"2025-03-14T17:50:57.379599Z","iopub.status.idle":"2025-03-14T17:50:57.395414Z","shell.execute_reply.started":"2025-03-14T17:50:57.379570Z","shell.execute_reply":"2025-03-14T17:50:57.394571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Define LSTM model\nmodel_lstm = Sequential()\nmodel_lstm.add(Embedding(input_dim=vocab_size,\n                         output_dim=embedding_dim,\n                         weights=[embedding_matrix],\n                         input_length=maxlen,\n                         trainable=False))\nmodel_lstm.add(LSTM(128))\nmodel_lstm.add(Dropout(0.5))\nmodel_lstm.add(Dense(1, activation='sigmoid'))\n\n# Compile model\nmodel_lstm.compile(optimizer=Adam(learning_rate=0.001),\n                   loss='binary_crossentropy',\n                   metrics=['accuracy'])\n\n\n\n# Train\nhistory_lstm = model_lstm.fit(X_train, y_train,\n                              epochs=30,\n                              batch_size=64,\n                              validation_data=(X_test, y_test),\n                              class_weight=class_weights,\n                              verbose=1)\n\n# Evaluate\nloss_lstm, acc_lstm = model_lstm.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\n🔁 LSTM Test Accuracy: {acc_lstm:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T17:51:28.013499Z","iopub.execute_input":"2025-03-14T17:51:28.013805Z","iopub.status.idle":"2025-03-14T18:09:39.414677Z","shell.execute_reply.started":"2025-03-14T17:51:28.013782Z","shell.execute_reply":"2025-03-14T18:09:39.413800Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Define the model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size,\n                    output_dim=embedding_dim,\n                    weights=[embedding_matrix],\n                    input_length=maxlen,\n                    trainable=False))  # Use pre-trained embeddings (Word2Vec or GloVe)\n\n# Bidirectional LSTM with L2 regularization\nmodel.add(Bidirectional(LSTM(128, kernel_regularizer=l2(0.001))))\n\n# Dropout for regularization\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Model callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n\n\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=30,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    class_weight=class_weights,\n    callbacks=[early_stop, checkpoint],\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T19:11:35.822725Z","iopub.execute_input":"2025-03-14T19:11:35.823075Z","iopub.status.idle":"2025-03-14T19:22:14.495829Z","shell.execute_reply.started":"2025-03-14T19:11:35.823049Z","shell.execute_reply":"2025-03-14T19:22:14.495029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, acc = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"\\n✅ Final BiLSTM Test Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T19:26:54.947834Z","iopub.execute_input":"2025-03-14T19:26:54.948150Z","iopub.status.idle":"2025-03-14T19:27:06.020322Z","shell.execute_reply.started":"2025-03-14T19:26:54.948128Z","shell.execute_reply":"2025-03-14T19:27:06.019391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"hi\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nfrom sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size,\n                    output_dim=embedding_dim,\n                    weights=[embedding_matrix],\n                    input_length=maxlen,\n                    trainable=True))  # <-- trainable now\n\nmodel.add(SpatialDropout1D(0.3))  # better dropout\n\nmodel.add(Bidirectional(LSTM(128, return_sequences=True)))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n# Compile the model\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Model callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n\n\n\n# Train the model\nhistory = model.fit(\n    X_train, y_train,\n    epochs=30,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    class_weight=class_weights,\n    callbacks=[early_stop, checkpoint],\n    verbose=1\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T18:50:26.243960Z","iopub.execute_input":"2025-03-15T18:50:26.244247Z","iopub.status.idle":"2025-03-15T19:04:19.689486Z","shell.execute_reply.started":"2025-03-15T18:50:26.244225Z","shell.execute_reply":"2025-03-15T19:04:19.688815Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 27ms/step - accuracy: 0.6955 - loss: 0.5771 - val_accuracy: 0.7576 - val_loss: 0.4851\nEpoch 2/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - accuracy: 0.7612 - loss: 0.4844 - val_accuracy: 0.7825 - val_loss: 0.4455\nEpoch 3/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - accuracy: 0.7937 - loss: 0.4263 - val_accuracy: 0.7954 - val_loss: 0.4271\nEpoch 4/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - accuracy: 0.8191 - loss: 0.3789 - val_accuracy: 0.7962 - val_loss: 0.4394\nEpoch 5/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - accuracy: 0.8357 - loss: 0.3452 - val_accuracy: 0.8004 - val_loss: 0.4396\nEpoch 6/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 27ms/step - accuracy: 0.8461 - loss: 0.3201 - val_accuracy: 0.8002 - val_loss: 0.4468\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer\nimport tensorflow.keras.backend as K\n\nclass Attention(Layer):\n    def __init__(self, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n                                 initializer=\"glorot_uniform\", trainable=True)\n        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n                                 initializer=\"zeros\", trainable=True)\n        super(Attention, self).build(input_shape)\n\n    def call(self, x):\n        e = K.tanh(K.dot(x, self.W) + self.b)\n        e = K.squeeze(e, axis=-1)\n        alpha = K.softmax(e)\n        alpha = K.expand_dims(alpha, axis=-1)\n        context = x * alpha\n        context = K.sum(context, axis=1)\n        return context\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:09:52.394721Z","iopub.execute_input":"2025-03-15T19:09:52.395082Z","iopub.status.idle":"2025-03-15T19:09:52.402441Z","shell.execute_reply.started":"2025-03-15T19:09:52.395055Z","shell.execute_reply":"2025-03-15T19:09:52.401670Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Bidirectional, SpatialDropout1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Input layer\ninput_layer = Input(shape=(maxlen,))\nembedding_layer = Embedding(input_dim=vocab_size,\n                            output_dim=embedding_dim,\n                            weights=[embedding_matrix],\n                            input_length=maxlen,\n                            trainable=True)(input_layer)\n\nx = SpatialDropout1D(0.3)(embedding_layer)\n\nx = Bidirectional(LSTM(128, return_sequences=True))(x)\nx = Bidirectional(LSTM(64, return_sequences=True))(x)\n\n# Attention\nattention_output = Attention()(x)\n\nx = Dropout(0.5)(attention_output)\noutput_layer = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile\noptimizer = Adam(learning_rate=1e-4)  # slightly lower LR\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model_with_attention.keras', monitor='val_accuracy', save_best_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n\n# Train\nhistory = model.fit(\n    X_train, y_train,\n    epochs=30,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    class_weight=class_weights,\n    callbacks=[early_stop, checkpoint, lr_reduce],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:10:09.213044Z","iopub.execute_input":"2025-03-15T19:10:09.213337Z","iopub.status.idle":"2025-03-15T19:45:32.912544Z","shell.execute_reply.started":"2025-03-15T19:10:09.213315Z","shell.execute_reply":"2025-03-15T19:45:32.911871Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 28ms/step - accuracy: 0.6662 - loss: 0.6048 - val_accuracy: 0.7372 - val_loss: 0.5228 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7201 - loss: 0.5508 - val_accuracy: 0.7543 - val_loss: 0.5032 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7311 - loss: 0.5330 - val_accuracy: 0.7627 - val_loss: 0.4875 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7414 - loss: 0.5173 - val_accuracy: 0.7642 - val_loss: 0.4808 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7486 - loss: 0.5043 - val_accuracy: 0.7657 - val_loss: 0.4765 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7547 - loss: 0.4934 - val_accuracy: 0.7744 - val_loss: 0.4618 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7596 - loss: 0.4830 - val_accuracy: 0.7789 - val_loss: 0.4526 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7644 - loss: 0.4741 - val_accuracy: 0.7796 - val_loss: 0.4496 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7699 - loss: 0.4660 - val_accuracy: 0.7823 - val_loss: 0.4451 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7747 - loss: 0.4586 - val_accuracy: 0.7881 - val_loss: 0.4379 - learning_rate: 1.0000e-04\nEpoch 11/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7806 - loss: 0.4467 - val_accuracy: 0.7916 - val_loss: 0.4315 - learning_rate: 1.0000e-04\nEpoch 12/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7849 - loss: 0.4393 - val_accuracy: 0.7922 - val_loss: 0.4298 - learning_rate: 1.0000e-04\nEpoch 13/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7901 - loss: 0.4310 - val_accuracy: 0.7904 - val_loss: 0.4315 - learning_rate: 1.0000e-04\nEpoch 14/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7926 - loss: 0.4238 - val_accuracy: 0.7857 - val_loss: 0.4370 - learning_rate: 1.0000e-04\nEpoch 15/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7986 - loss: 0.4134 - val_accuracy: 0.7808 - val_loss: 0.4468 - learning_rate: 5.0000e-05\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, Dense, Bidirectional, SpatialDropout1D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.layers import Layer\nimport tensorflow.keras.backend as K\nimport numpy as np\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Compute class weights\nclass_weights_array = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\nclass_weights = dict(enumerate(class_weights_array))\n\n# Attention Layer\nclass Attention(Layer):\n    def __init__(self, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n                                 initializer=\"glorot_uniform\", trainable=True)\n        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n                                 initializer=\"zeros\", trainable=True)\n        super(Attention, self).build(input_shape)\n\n    def call(self, x):\n        e = K.tanh(K.dot(x, self.W) + self.b)\n        e = K.squeeze(e, axis=-1)\n        alpha = K.softmax(e)\n        alpha = K.expand_dims(alpha, axis=-1)\n        context = x * alpha\n        context = K.sum(context, axis=1)\n        return context\n\n# Model architecture\ninput_layer = Input(shape=(maxlen,))\nembedding_layer = Embedding(input_dim=vocab_size,\n                            output_dim=embedding_dim,\n                            weights=[embedding_matrix],\n                            input_length=maxlen,\n                            trainable=True)(input_layer)\n\nx = SpatialDropout1D(0.3)(embedding_layer)\nx = Bidirectional(LSTM(128, return_sequences=True))(x)\nx = Bidirectional(LSTM(64, return_sequences=True))(x)\nx = Attention()(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile model\noptimizer = Adam(learning_rate=1e-4)\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint('best_model_with_attention.keras', monitor='val_accuracy', save_best_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n\n# Train model (no EarlyStopping)\nhistory = model.fit(\n    X_train, y_train,\n    epochs=30,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    class_weight=class_weights,\n    callbacks=[checkpoint, lr_reduce],\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:48:54.464944Z","iopub.execute_input":"2025-03-15T19:48:54.465250Z","iopub.status.idle":"2025-03-15T20:59:38.384051Z","shell.execute_reply.started":"2025-03-15T19:48:54.465228Z","shell.execute_reply":"2025-03-15T20:59:38.383308Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 28ms/step - accuracy: 0.6661 - loss: 0.6054 - val_accuracy: 0.7434 - val_loss: 0.5157 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7248 - loss: 0.5479 - val_accuracy: 0.7537 - val_loss: 0.5005 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7347 - loss: 0.5296 - val_accuracy: 0.7603 - val_loss: 0.4858 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7413 - loss: 0.5140 - val_accuracy: 0.7663 - val_loss: 0.4737 - learning_rate: 1.0000e-04\nEpoch 5/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7472 - loss: 0.5049 - val_accuracy: 0.7715 - val_loss: 0.4659 - learning_rate: 1.0000e-04\nEpoch 6/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7559 - loss: 0.4917 - val_accuracy: 0.7757 - val_loss: 0.4577 - learning_rate: 1.0000e-04\nEpoch 7/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7608 - loss: 0.4818 - val_accuracy: 0.7795 - val_loss: 0.4520 - learning_rate: 1.0000e-04\nEpoch 8/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7660 - loss: 0.4730 - val_accuracy: 0.7823 - val_loss: 0.4504 - learning_rate: 1.0000e-04\nEpoch 9/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7711 - loss: 0.4631 - val_accuracy: 0.7778 - val_loss: 0.4488 - learning_rate: 1.0000e-04\nEpoch 10/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7762 - loss: 0.4534 - val_accuracy: 0.7815 - val_loss: 0.4453 - learning_rate: 1.0000e-04\nEpoch 11/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7802 - loss: 0.4455 - val_accuracy: 0.7884 - val_loss: 0.4333 - learning_rate: 1.0000e-04\nEpoch 12/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7856 - loss: 0.4385 - val_accuracy: 0.7863 - val_loss: 0.4360 - learning_rate: 1.0000e-04\nEpoch 13/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7906 - loss: 0.4305 - val_accuracy: 0.7906 - val_loss: 0.4278 - learning_rate: 1.0000e-04\nEpoch 14/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.7935 - loss: 0.4236 - val_accuracy: 0.7913 - val_loss: 0.4284 - learning_rate: 1.0000e-04\nEpoch 15/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.7982 - loss: 0.4152 - val_accuracy: 0.7791 - val_loss: 0.4454 - learning_rate: 1.0000e-04\nEpoch 16/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 28ms/step - accuracy: 0.8050 - loss: 0.4031 - val_accuracy: 0.7954 - val_loss: 0.4226 - learning_rate: 5.0000e-05\nEpoch 17/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8084 - loss: 0.3991 - val_accuracy: 0.7933 - val_loss: 0.4275 - learning_rate: 5.0000e-05\nEpoch 18/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8116 - loss: 0.3936 - val_accuracy: 0.7904 - val_loss: 0.4286 - learning_rate: 5.0000e-05\nEpoch 19/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8139 - loss: 0.3896 - val_accuracy: 0.7936 - val_loss: 0.4260 - learning_rate: 2.5000e-05\nEpoch 20/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8152 - loss: 0.3859 - val_accuracy: 0.7915 - val_loss: 0.4281 - learning_rate: 2.5000e-05\nEpoch 21/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8191 - loss: 0.3800 - val_accuracy: 0.7932 - val_loss: 0.4256 - learning_rate: 1.2500e-05\nEpoch 22/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8187 - loss: 0.3784 - val_accuracy: 0.7916 - val_loss: 0.4296 - learning_rate: 1.2500e-05\nEpoch 23/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8182 - loss: 0.3795 - val_accuracy: 0.7921 - val_loss: 0.4287 - learning_rate: 6.2500e-06\nEpoch 24/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8193 - loss: 0.3764 - val_accuracy: 0.7945 - val_loss: 0.4260 - learning_rate: 6.2500e-06\nEpoch 25/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8196 - loss: 0.3772 - val_accuracy: 0.7936 - val_loss: 0.4282 - learning_rate: 3.1250e-06\nEpoch 26/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8193 - loss: 0.3774 - val_accuracy: 0.7939 - val_loss: 0.4263 - learning_rate: 3.1250e-06\nEpoch 27/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8189 - loss: 0.3774 - val_accuracy: 0.7931 - val_loss: 0.4283 - learning_rate: 1.5625e-06\nEpoch 28/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8185 - loss: 0.3793 - val_accuracy: 0.7935 - val_loss: 0.4273 - learning_rate: 1.5625e-06\nEpoch 29/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8197 - loss: 0.3750 - val_accuracy: 0.7934 - val_loss: 0.4280 - learning_rate: 7.8125e-07\nEpoch 30/30\n\u001b[1m5054/5054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 28ms/step - accuracy: 0.8196 - loss: 0.3770 - val_accuracy: 0.7935 - val_loss: 0.4278 - learning_rate: 7.8125e-07\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}